{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kizombaciao/Working-with-MULTIPLE-PDF-Files-in-LangChain-ChatGPT-for-your-Data/blob/main/Multiple_PDF_files.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installation"
      ],
      "metadata": {
        "id": "mQkpFI2UQ1nQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.youtube.com/watch?v=s5LhRdh5fu4"
      ],
      "metadata": {
        "id": "Z86W7fPGHRaZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The unstructured Python package is a free and open-source toolkit that makes it easy to prepare unstructured data like PDFs, HTML and Word Documents for downstream data science tasks. It can be used to perform tasks such as parsing documents, extracting text, and cleaning data.\n",
        "\n",
        "The unstructured Python package is available on PyPI and can be installed using the pip package manager. Once installed, you can use the unstructured library to create a pipeline for processing documents. The pipeline can be customized to fit your specific needs.\n",
        "\n",
        "The unstructured Python package is a powerful tool for working with unstructured data. It can be used to prepare data for machine learning, natural language processing, and other data science tasks.\n",
        "\n"
      ],
      "metadata": {
        "id": "o3aDDLQWHYaS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain\n",
        "!pip install unstructured\n",
        "!pip install openai\n",
        "!pip install chromadb\n",
        "!pip install Cython\n",
        "!pip install tiktoken"
      ],
      "metadata": {
        "id": "cNOqE4rcLyy-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Required Packages"
      ],
      "metadata": {
        "id": "3zwqefnqQ5XT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import UnstructuredPDFLoader\n",
        "from langchain.indexes import VectorstoreIndexCreator"
      ],
      "metadata": {
        "id": "sZyuQZbmMHRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### OpenAI API Key"
      ],
      "metadata": {
        "id": "7xTspt2HQ-IF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get your API keys from openai, you will need to create an account. \n",
        "# Here is the link to get the keys: https://platform.openai.com/account/billing/overview\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\""
      ],
      "metadata": {
        "id": "rRLZqAttMPPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Connect Google Drive"
      ],
      "metadata": {
        "id": "iXTO--zGRJYP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# connect your Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "root_dir = \"/content/gdrive/My Drive/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bN-sa7AeKc12",
        "outputId": "d996ea8a-a11a-4e1a-d916-68fa5da86332"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_folder_path = f'{root_dir}/data/'\n",
        "os.listdir(pdf_folder_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OW-sc_UnKc9Z",
        "outputId": "e8f2b7d9-586c-4c2f-ca7d-87e7f4823a87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['state_of_the_union_part1.pdf', 'state_of_the_union_part2.pdf']"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VsMsK16kKdDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Multiple PDF files"
      ],
      "metadata": {
        "id": "GFZhxGOrRRK_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# location of the pdf file/files. \n",
        "loaders = [UnstructuredPDFLoader(os.path.join(pdf_folder_path, fn)) for fn in os.listdir(pdf_folder_path)]"
      ],
      "metadata": {
        "id": "TF1vWIDGK3-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaders"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SI_beYYnK4By",
        "outputId": "f8a00273-4024-4d1b-af0c-a49ba54f887d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<langchain.document_loaders.pdf.UnstructuredPDFLoader at 0x7f590c1e2df0>,\n",
              " <langchain.document_loaders.pdf.UnstructuredPDFLoader at 0x7f59043b66a0>]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vector Store \n",
        "Chroma as vectorstore to index and search embeddings\n",
        "\n",
        "\n",
        "There are three main steps going on after the documents are loaded:\n",
        "\n",
        "- Splitting documents into chunks\n",
        "\n",
        "- Creating embeddings for each document\n",
        "\n",
        "- Storing documents and embeddings in a vectorstore\n"
      ],
      "metadata": {
        "id": "pFehORDuRYFN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index = VectorstoreIndexCreator().from_loaders(loaders)\n",
        "index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ho9v_0qXK4E8",
        "outputId": "96e07c13-a03c-4bd0-aba6-4ab0e7638ae7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:unstructured:detectron2 is not installed. Cannot use the hi_res partitioning strategy. Falling back to partitioning with the fast strategy.\n",
            "WARNING:unstructured:detectron2 is not installed. Cannot use the hi_res partitioning strategy. Falling back to partitioning with the fast strategy.\n",
            "WARNING:chromadb:Using embedded DuckDB without persistence: data will be transient\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VectorStoreIndexWrapper(vectorstore=<langchain.vectorstores.chroma.Chroma object at 0x7f5906573910>)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index.query('What was the main topic of the address?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "YihqyjcSK4Ic",
        "outputId": "3eeb08ae-c6bb-419b-de46-e613dd2f2a5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The main topic of the address was investing in America and rebuilding infrastructure.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "znd10P9tQSMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_folder_path = '/content/gdrive/My Drive/data_2/'\n",
        "os.listdir(pdf_folder_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYqMKf8SQSP-",
        "outputId": "d98a01b6-665b-4a8b-bd84-915273bf8a6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['2008.10010.pdf', '2023_GPT4All_Technical_Report.pdf']"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# location of the pdf file/files. \n",
        "loaders = [UnstructuredPDFLoader(os.path.join(pdf_folder_path, fn)) for fn in os.listdir(pdf_folder_path)]\n",
        "index = VectorstoreIndexCreator().from_loaders(loaders)\n",
        "index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erW9azEgQUuE",
        "outputId": "f317a7d2-c978-4911-9ecc-6cbf465d5975"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:unstructured:detectron2 is not installed. Cannot use the hi_res partitioning strategy. Falling back to partitioning with the fast strategy.\n",
            "WARNING:unstructured:detectron2 is not installed. Cannot use the hi_res partitioning strategy. Falling back to partitioning with the fast strategy.\n",
            "WARNING:chromadb:Using embedded DuckDB without persistence: data will be transient\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VectorStoreIndexWrapper(vectorstore=<langchain.vectorstores.chroma.Chroma object at 0x7f59043d1040>)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index.query('How was the GPT4all model trained?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8hKZkf_5QfV1",
        "outputId": "5606b684-364f-4673-9970-8674ce28c454"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The GPT4all model was trained with LoRA (Hu et al., 2021) on the 437,605 post-processed examples for four epochs.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index.query_with_sources('How was the GPT4all model trained?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vkT_71dZJwH",
        "outputId": "c7f2d354-8a4c-4ac4-a845-76058b35e518"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': 'How was the GPT4all model trained?',\n",
              " 'answer': ' The GPT4all model was trained with LoRA on 437,605 post-processed examples for four epochs. The data was collected using the GPT-3.5-Turbo OpenAI API and was curated to ensure a diverse distribution of prompt topics and model responses.\\n\\n',\n",
              " 'sources': '/content/gdrive/My Drive/data_2/2023_GPT4All_Technical_Report.pdf'}"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index.query_with_sources('Who wrote the lip sync paper? ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-cCTPPSZJ0c",
        "outputId": "1e789d65-c9ad-4c75-ec3d-f0feedf3f20d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': 'Who wrote the lip sync paper? ',\n",
              " 'answer': ' The lip sync paper was written by K R Prajwal, Vinay P. Namboodiri, Rudrabha Mukhopadhyay, and C V Jawahar.\\n',\n",
              " 'sources': '/content/gdrive/My Drive/data_2/2008.10010.pdf'}"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5Or_wmr6ZJ6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index.query_with_sources('How was the GPT4all model trained?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbUZ9sQiQnKm",
        "outputId": "3f057da4-48fd-4b20-bcaa-aa796876a3ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': 'How was the GPT4all model trained?',\n",
              " 'answer': ' The GPT4all model was trained with LoRA on 437,605 post-processed examples for four epochs. Detailed model hyper-parameters and training code can be found in the associated repository and model training log.\\n',\n",
              " 'sources': '/content/gdrive/My Drive/data_2/2023_GPT4All_Technical_Report.pdf'}"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index.query_with_sources('Who wrote the lip sync paper? ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyV0UoN5QtJd",
        "outputId": "72da9379-4b09-4d49-b676-77e6815ab6c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': 'Who wrote the lip sync paper? ',\n",
              " 'answer': ' The lip sync paper was written by K R Prajwal, Vinay P. Namboodiri, Rudrabha Mukhopadhyay, and C V Jawahar.\\n',\n",
              " 'sources': '/content/gdrive/My Drive/data_2/2008.10010.pdf'}"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2qtmKGd7Y70z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Disclaimer:\n",
        "Note: OpenAI provides a free API key for initial testing. Once you move to a paid subscription, calling the API in the way demonstrated in this example will incur monetary charges. Refer to OpenAI's pricing information for details.\n",
        "\n",
        "Be aware that information, such as files to train OpenAI's LLM can become public if applied in the way this demo demonstrates. Refer to OpenAI's usage policy for details.\n",
        "\n",
        "Do not use for actual tax filing purposes. This demo is for educational purposes only and for demonstrating machine learning methods. The author makes no claims that the outcomes shown here or any outcomes that could be produced by this method are accurate or reliable."
      ],
      "metadata": {
        "id": "bR32r8BozfIM"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1nLYj55NzhJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyPI, or the Python Package Index, is a public repository for Python packages. It is the official third-party software repository for Python, and it is analogous to the CPAN repository for Perl and to the CRAN repository for R. PyPI is run by the Python Software Foundation, a charity.\n",
        "\n",
        "PyPI primarily hosts Python packages in the form of archives called sdists (source distributions) or precompiled \"wheels.\" PyPI as an index allows users to search for packages by keywords or by filters against their metadata, such as free software license or compatibility with POSIX. A single entry on PyPI is able to store, aside from just a package and its metadata, previous releases of the package, precompiled wheels (e.g. containing DLLs on Windows), as well as different forms for different operating systems and Python versions."
      ],
      "metadata": {
        "id": "D8ChKIwFHlY6"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e4vtlHJMHlqB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}